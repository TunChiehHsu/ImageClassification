{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-a58259f1deba>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-a58259f1deba>:9: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# number 1 to 10 data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)\n",
    "# Load training and eval data\n",
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys):\n",
    "    global prediction\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs, keep_prob: 1})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), v_ys)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) # change type from Boolean -> Float\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys, keep_prob: 1})\n",
    "    return result\n",
    "\n",
    "def weight_variable(shape):\n",
    "    inital = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(inital)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    inital = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(inital)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define placeholder for inputs to network\n",
    "\n",
    "xs = tf.placeholder(tf.float32, [None, 784]) # 28x28\n",
    "\n",
    "# transfer label to one_hot\n",
    "ys = tf.placeholder(tf.int32, [None])\n",
    "yss = tf.one_hot(ys, depth = 10)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "x_image = tf.reshape(xs, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conv1 layer ##\n",
    "W_conv1 = weight_variable([5, 5, 1, 32]) #patch 5x5, in channel size 1, out size 32\n",
    "## pool1 layer ##\n",
    "b_conv1 = bias_variable([32])\n",
    "#Combine\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) #output size 28x28x32\n",
    "h_pool1 = max_pool_2x2(h_conv1) #output size 14x14x32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conv2 layer ##\n",
    "W_conv2 = weight_variable([5, 5, 32, 64]) #patch 5x5, in channel size 32, out size 64\n",
    "## pool2 layer ##\n",
    "b_conv2 = bias_variable([64])\n",
    "#Combine\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2) #output size 14x14x64\n",
    "h_pool2 = max_pool_2x2(h_conv2) #output size 7x7x64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fc1 layer ##\n",
    "\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64]) #[n_samples, 7,7,64]  => [n_samples, 7*7*64]\n",
    "\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "## output layer ##\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(yss * tf.log(prediction),\n",
    "                                              reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "0.0797\n",
      "(10000,)\n",
      "0.7762\n",
      "(10000,)\n",
      "0.8503\n",
      "(10000,)\n",
      "0.9039\n",
      "(10000,)\n",
      "0.9219\n",
      "(10000,)\n",
      "0.929\n",
      "(10000,)\n",
      "0.9335\n",
      "(10000,)\n",
      "0.9396\n",
      "(10000,)\n",
      "0.9472\n",
      "(10000,)\n",
      "0.9503\n",
      "(10000,)\n",
      "0.9526\n",
      "(10000,)\n",
      "0.956\n",
      "(10000,)\n",
      "0.9574\n",
      "(10000,)\n",
      "0.9593\n",
      "(10000,)\n",
      "0.9596\n",
      "(10000,)\n",
      "0.9632\n",
      "(10000,)\n",
      "0.9648\n",
      "(10000,)\n",
      "0.9675\n",
      "(10000,)\n",
      "0.9685\n",
      "(10000,)\n",
      "0.966\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys, keep_prob:0.5})\n",
    "    if i % 50 == 0:\n",
    "        print(compute_accuracy(\n",
    "            mnist.test.images, mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sess.run(prediction, feed_dict={xs: batch_xs, keep_prob: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sckit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filename = os.path.join(skimage.data_dir, 'moon.png')\n",
    "from skimage import io\n",
    "moon = io.imread(\"/Users/tunchiehhsu/Desktop/googliser/googliser/damaged_boxes/google-image(0002).jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.image.resize_images(moon,[100,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot reshape a tensor with 1439055 elements to shape [100,100,3] (30000 elements) for 'Reshape_17' (op: 'Reshape') with input shapes: [565,849,3], [3] and with input tensors computed as partial shapes: input[1] = [100,100,3].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1575\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Cannot reshape a tensor with 1439055 elements to shape [100,100,3] (30000 elements) for 'Reshape_17' (op: 'Reshape') with input shapes: [565,849,3], [3] and with input tensors computed as partial shapes: input[1] = [100,100,3].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-e7e2baa474e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6198\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 6199\u001b[0;31m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   6200\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6201\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 instructions)\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    456\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3153\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3154\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3155\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3156\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1729\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1730\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1731\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot reshape a tensor with 1439055 elements to shape [100,100,3] (30000 elements) for 'Reshape_17' (op: 'Reshape') with input shapes: [565,849,3], [3] and with input tensors computed as partial shapes: input[1] = [100,100,3]."
     ]
    }
   ],
   "source": [
    "tf.reshape(moon,[100,100,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12bd99ac8>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADT1JREFUeJzt3W+MHPV9x/HPx+ezDYY2uLiXi2NqoBDJoq1TXZ1KWFFaSmooiXEe0Fhq6kgol5ZQNVIeFLkPykOraohQlUIvwcJUKUmlhOBGVoJjRaXQ1OFArjE4xcQ4iS3/gTitHSqMff72wY3RYW5nl92ZnT2+75d0ut35zux8NfbnZnZ/u/tzRAhAPvOabgBAMwg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk5vdzZwu8MBZpcT93CaTyml7V63HanazbU/htr5V0r6QhSV+OiM1l6y/SYn3AN/SySwAldsXOjtft+rLf9pCkL0q6SdJKSRtsr+z28QD0Vy/P+VdLejEiDkTE65K+KmldNW0BqFsv4V8m6acz7h8qlr2J7XHbk7Ynz+h0D7sDUKXaX+2PiImIGIuIsWEtrHt3ADrUS/gPS1o+4/57i2UA5oBewv+UpGtsX2l7gaSPS9pWTVsA6tb1UF9EnLV9p6TvaHqob0tEPFdZZwBq1dM4f0Rsl7S9ol4A9BFv7wWSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpnmbptX1Q0ilJU5LORsRYFU0BqF9P4S/8XkS8UsHjAOgjLvuBpHoNf0h6zPbTtseraAhAf/R62b8mIg7b/lVJO2z/MCIen7lC8UdhXJIW6eIedwegKj2d+SPicPH7uKRHJK2eZZ2JiBiLiLFhLexldwAq1HX4bS+2fen525I+LGlvVY0BqFcvl/0jkh6xff5x/jkivl1JVwBq13X4I+KApN+qsBcAfcRQH5AU4QeSIvxAUoQfSIrwA0kRfiCpKj7V947wwv1veXPim7z4kftb1lY+8cnSbeftu6S0ftU/Hiitnz1ytLQOdIMzP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTh/4V17yg/FyT96rWXt+TUPlm57bk2U1h/7k8Wl9R3/e11pfft3fqe03qTrf7/197vMU/lx2b95ZWn9om/+oKueMI0zP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8k5YjysdYq/ZKXxAd8Q9/2V6XXbmn9ef+f3FK+7Xdvuqe0fsX8i7ppqSPz5NL6uTZj7XVq19uvP/pnpfVr72Cc/0K7YqdOxonyA1vgzA8kRfiBpAg/kBThB5Ii/EBShB9IivADSbX9PL/tLZJukXQ8Iq4rli2R9DVJKyQdlHRbRPy8vjabt+hbrceUr/1W+bZ/MfKx0vrR9VeX1tf9+b+V1pfMf7VlbZ7PlW57Lur9+7/+0uda1kaHLq513yjXyb/8g5LWXrDsLkk7I+IaSTuL+wDmkLbhj4jHJZ24YPE6SVuL21sl3VpxXwBq1u0130hEHCluH5U0UlE/APqk5yd8Mf3hgJZvELc9bnvS9uQZne51dwAq0m34j9kelaTi9/FWK0bERESMRcTYsBZ2uTsAVes2/NskbSxub5T0aDXtAOiXtuG3/bCk70t6n+1Dtm+XtFnSjbb3S/qD4j6AOaTtOH9EbGhRmpsfzG/A1LGWz4okSUvvL6//x/0L2uyhXb05e39wY8vaPyx7so+d4EK8ww9IivADSRF+ICnCDyRF+IGkCD+QFFN0o1ZDbv3V4ENuc+7p6Auo0S3O/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOP8qNVUtB6sn4ryrxVvcPbwFDjzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBSjPOjJ0PXlk8vPr704ZJq+X+/93yPD/TXiTM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTVdpzf9hZJt0g6HhHXFcvulvQpSS8Xq22KiO11NYnBde6XLy6t/+aCoa4f+9KXXi2t83H/3nRy5n9Q0tpZln8hIlYVPwQfmGPahj8iHpd0og+9AOijXp7z32l7j+0tti+rrCMAfdFt+O+TdLWkVZKOSPp8qxVtj9uetD15Rqe73B2AqnUV/og4FhFTEXFO0pckrS5ZdyIixiJibFgLu+0TQMW6Cr/t0Rl310vaW007APqlk6G+hyV9SNLltg9J+htJH7K9StOjLQclfbrGHgHUoG34I2LDLIsfqKEXzEEvffSSrrd98nT5hefQz06V1s92vWdIvMMPSIvwA0kRfiApwg8kRfiBpAg/kBRf3Y2e3Lj2mdL6PLX++u1NL3ysdNvFLx3oqid0hjM/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFOD968qeXP1FaP1dyfjm5492l2y4W4/x14swPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kxzo9S869aUVp/17wn2zzCosp6QbU48wNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUm3H+W0vl/SQpBFJIWkiIu61vUTS1yStkHRQ0m0R8fP6WkUdPLygtD715TOl9Svndz+O/+7//L+ut0XvOjnzn5X0uYhYKel3JX3G9kpJd0naGRHXSNpZ3AcwR7QNf0QciYhnitunJO2TtEzSOklbi9W2Srq1riYBVO9tPee3vULS+yXtkjQSEUeK0lFNPy0AMEd0HH7bl0j6uqTPRsTJmbWICE2/HjDbduO2J21PntHpnpoFUJ2Owm97WNPB/0pEfKNYfMz2aFEflXR8tm0jYiIixiJibFgLq+gZQAXaht+2JT0gaV9E3DOjtE3SxuL2RkmPVt8egLp08pHe6yV9QtKztncXyzZJ2izpX2zfLunHkm6rp0XUaWhkaWn9m+/b1tPjr923vmVt/pO7W9ZQv7bhj4gnpJaTrN9QbTsA+oV3+AFJEX4gKcIPJEX4gaQIP5AU4QeS4qu7k9t/xxWl9XktR3k7M3VP6498zNdPenps9IYzP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTh/ch/5w12l9XOzfzvbG774P1eX1i/69x+WPDaaxJkfSIrwA0kRfiApwg8kRfiBpAg/kBThB5JinP+dbvVvlJbvuPy+Ng9wUWn1ob+/qbS+9NT32zw+msKZH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSajvOb3u5pIckjUgKSRMRca/tuyV9StLLxaqbImJ7XY2iO6eXLiqtXzG/fBy/ndF//XFp/WxPj446dfImn7OSPhcRz9i+VNLTtncUtS9ExN/V1x6AurQNf0QckXSkuH3K9j5Jy+puDEC93tZzftsrJL1f0vnvfrrT9h7bW2xf1mKbcduTtifP6HRPzQKoTsfht32JpK9L+mxEnJR0n6SrJa3S9JXB52fbLiImImIsIsaGtbCClgFUoaPw2x7WdPC/EhHfkKSIOBYRUxFxTtKXJK2ur00AVWsbftuW9ICkfRFxz4zlozNWWy9pb/XtAahLJ6/2Xy/pE5Ketb27WLZJ0gbbqzQ9/HdQ0qdr6RA9uXjXgdL6H/9obWl97+H3lNaveqX1V3NjsHXyav8T0qyTtDOmD8xhvMMPSIrwA0kRfiApwg8kRfiBpAg/kBRf3f0ON/XKz0rrr36wfPsr3/jE9uzKJ/DGIOPMDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJOaJ/I7W2X5Y087ueL5f0St8aeHsGtbdB7Uuit25V2duvRcTSTlbsa/jfsnN7MiLGGmugxKD2Nqh9SfTWraZ647IfSIrwA0k1Hf6JhvdfZlB7G9S+JHrrViO9NfqcH0Bzmj7zA2hII+G3vdb2f9t+0fZdTfTQiu2Dtp+1vdv2ZMO9bLF93PbeGcuW2N5he3/xe9Zp0hrq7W7bh4tjt9v2zQ31ttz292w/b/s5239ZLG/02JX01chx6/tlv+0hSS9IulHSIUlPSdoQEc/3tZEWbB+UNBYRjY8J2/6gpF9IeigiriuW/a2kExGxufjDeVlE/NWA9Ha3pF80PXNzMaHM6MyZpSXdKumTavDYlfR1mxo4bk2c+VdLejEiDkTE65K+KmldA30MvIh4XNKJCxavk7S1uL1V0/95+q5FbwMhIo5ExDPF7VOSzs8s3eixK+mrEU2Ef5mkn864f0iDNeV3SHrM9tO2x5tuZhYjxbTpknRU0kiTzcyi7czN/XTBzNIDc+y6mfG6arzg91ZrIuK3Jd0k6TPF5e1AiunnbIM0XNPRzM39MsvM0m9o8th1O+N11ZoI/2FJy2fcf2+xbCBExOHi93FJj2jwZh8+dn6S1OL38Yb7ecMgzdw828zSGoBjN0gzXjcR/qckXWP7StsLJH1c0rYG+ngL24uLF2Jke7GkD2vwZh/eJmljcXujpEcb7OVNBmXm5lYzS6vhYzdwM15HRN9/JN2s6Vf8fyTpr5vooUVfV0n6r+LnuaZ7k/Swpi8Dz2j6tZHbJf2KpJ2S9kv6rqQlA9TbP0l6VtIeTQdttKHe1mj6kn6PpN3Fz81NH7uSvho5brzDD0iKF/yApAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyT1/7PZ8uaEg5XeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
